{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWNk_oMDq_0h"
   },
   "source": [
    "# Neural Network SMS Text Classifier\n",
    "\n",
    "This is my solution for the Neural Network SMS Text Classifier project from FreeCodeCamp. Instructions for this project can be found [here](https://www.freecodecamp.org/learn/machine-learning-with-python/machine-learning-with-python-projects/neural-network-sms-text-classifier).\n",
    "\n",
    "## Introduction\n",
    "For this project, I am going to use PyTorch instead of TensorFlow.\n",
    "The reason is that it's more relevant for me to learn.\n",
    "Learning a new framework is challenging enough on its own, so to simplify the task, the Recurrent Neural Network (RNN) model with LSTM unit will be used.\n",
    "\n",
    "Although the data has already been prepared for us, we will begin with a bit of EDA (Explorary Data Analysis). Then, we set up the necessary components: a tokenizer, data preprocessing steps, and the LSTM-based model. Our approach includes employing cross-validation to optimize hyperparameters for effective training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RZOuS9LWQvv"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1692428189864,
     "user": {
      "displayName": "Eugene Emelyanov (yemel)",
      "userId": "15307913813243875076"
     },
     "user_tz": -120
    },
    "id": "lMHwYXHXCar3",
    "outputId": "763a42d1-29c1-45a2-c037-0ddbcac18af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-19 06:56:28--  https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
      "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.2.33, 104.26.3.33, 172.67.70.149, ...\n",
      "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.2.33|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 358233 (350K) [text/tab-separated-values]\n",
      "Saving to: ‘train-data.tsv’\n",
      "\n",
      "\r",
      "train-data.tsv        0%[                    ]       0  --.-KB/s               \r",
      "train-data.tsv      100%[===================>] 349.84K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2023-08-19 06:56:29 (17.1 MB/s) - ‘train-data.tsv’ saved [358233/358233]\n",
      "\n",
      "--2023-08-19 06:56:29--  https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
      "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.2.33, 104.26.3.33, 172.67.70.149, ...\n",
      "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.2.33|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 118774 (116K) [text/tab-separated-values]\n",
      "Saving to: ‘valid-data.tsv’\n",
      "\n",
      "valid-data.tsv      100%[===================>] 115.99K  --.-KB/s    in 0.007s  \n",
      "\n",
      "2023-08-19 06:56:29 (15.8 MB/s) - ‘valid-data.tsv’ saved [118774/118774]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get data files\n",
    "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
    "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
    "\n",
    "train_file_path = \"train-data.tsv\"\n",
    "test_file_path = \"valid-data.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1692428196675,
     "user": {
      "displayName": "Eugene Emelyanov (yemel)",
      "userId": "15307913813243875076"
     },
     "user_tz": -120
    },
    "id": "g_h508FEClxO",
    "outputId": "65ff7089-035c-47fb-ac4d-c86114f049de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-25300e3e-ae43-4ebc-bc1e-038590c6c40a\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>ahhhh...just woken up!had a bad dream about u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>you can never do nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>now u sound like manky scouse boy steve,like! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>mum say we wan to go then go... then she can s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>never y lei... i v lazy... got wat? dat day ü ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25300e3e-ae43-4ebc-bc1e-038590c6c40a')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-25300e3e-ae43-4ebc-bc1e-038590c6c40a button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-25300e3e-ae43-4ebc-bc1e-038590c6c40a');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-c7d99fb3-736c-4b6b-8f58-430c8ee19d0c\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c7d99fb3-736c-4b6b-8f58-430c8ee19d0c')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const charts = await google.colab.kernel.invokeFunction(\n",
       "          'suggestCharts', [key], {});\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-c7d99fb3-736c-4b6b-8f58-430c8ee19d0c button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  ahhhh...just woken up!had a bad dream about u ...\n",
       "1   ham                           you can never do nothing\n",
       "2   ham  now u sound like manky scouse boy steve,like! ...\n",
       "3   ham  mum say we wan to go then go... then she can s...\n",
       "4   ham  never y lei... i v lazy... got wat? dat day ü ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "train_df = pd.read_table(train_file_path, names=['label', 'text'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 529,
     "status": "ok",
     "timestamp": 1692428202116,
     "user": {
      "displayName": "Eugene Emelyanov (yemel)",
      "userId": "15307913813243875076"
     },
     "user_tz": -120
    },
    "id": "zOMKywn4zReN",
    "outputId": "9fbd4fa0-bf5e-4482-8560-4d5f651b6513"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     3619\n",
       "spam     560\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to know how well the dataset is balanced\n",
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "executionInfo": {
     "elapsed": 1287,
     "status": "ok",
     "timestamp": 1692428224664,
     "user": {
      "displayName": "Eugene Emelyanov (yemel)",
      "userId": "15307913813243875076"
     },
     "user_tz": -120
    },
    "id": "-UhFnaobi9BD",
    "outputId": "0d2f9594-a0ec-4936-a8f8-4c7c548b6211"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of labeled messages')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It looks like we have quite unbalanced dataset\n",
    "count = train_df['label'].value_counts()\n",
    "plt.bar(count.index, count )\n",
    "plt.title('Number of labeled messages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1692428237531,
     "user": {
      "displayName": "Eugene Emelyanov (yemel)",
      "userId": "15307913813243875076"
     },
     "user_tz": -120
    },
    "id": "K2hS_rnRdrNT",
    "outputId": "2f48d24a-e7ef-448c-912d-6af78c37ef15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     1205\n",
       "spam     187\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load testing dataset\n",
    "test_df = pd.read_table(test_file_path, names=['label', 'text'])\n",
    "test_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8991,
     "status": "ok",
     "timestamp": 1692428258598,
     "user": {
      "displayName": "Eugene Emelyanov (yemel)",
      "userId": "15307913813243875076"
     },
     "user_tz": -120
    },
    "id": "JFHIHOZbdri_",
    "outputId": "27a738fa-47f7-40cf-bf2d-6cf3db4a1206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:  ['ahhhh', '...', 'just', 'woken', 'up!had', 'a', 'bad', 'dream', 'about', 'u', 'tho', ',', 'so', 'i', 'do', 'nt', 'like', 'u', 'right', 'now', ':)', 'i', 'did', 'nt', 'know', 'anything', 'about', 'comedy', 'night', 'but', 'i', 'guess', 'i', 'm', 'up', 'for', 'it', '.']\n",
      "Vocabulary size:  3623\n"
     ]
    }
   ],
   "source": [
    "# Define the tokenizer\n",
    "def get_tokens(data):\n",
    "    for text in data:\n",
    "        yield tokenizer(text)\n",
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "# Build the vocabulary\n",
    "vocab = build_vocab_from_iterator(get_tokens(train_df['text']), specials=['<unk>'], min_freq=2)\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Calculate max sequence length\n",
    "max_sequence_len = train_df['text'].apply( lambda x: len( tokenizer(x) ) ).max()\n",
    "\n",
    "# Check tokenizer\n",
    "with torch.no_grad():\n",
    "    text = train_df.loc[0, 'text']\n",
    "    tokens = tokenizer(text)\n",
    "    print('Tokens: ', tokens)\n",
    "    print('Vocabulary size: ', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1210,
     "status": "ok",
     "timestamp": 1692428262872,
     "user": {
      "displayName": "Eugene Emelyanov (yemel)",
      "userId": "15307913813243875076"
     },
     "user_tz": -120
    },
    "id": "T1aseD1Ddrr5",
    "outputId": "6f9a97e7-7641-46e3-b41f-8c5c665f3e4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data: tensor([   0,   10,   47, 3589,    0,    7,  427,  826,   95,   11,  864,    5,\n",
      "          34,    2,   20,   52,   71,   11,  183,   30,  110,    2,   89,   52,\n",
      "          69,  187,   95, 1662,  130,   33,    2,  332,    2,  155,   55,   18,\n",
      "          17,    1])\n",
      "Sample Label: tensor(0)\n",
      "Data Shape: torch.Size([64, 70])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 42])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 42])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 68])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 40])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 41])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 175])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 43])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 146])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 166])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 47])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 94])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 43])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 56])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 70])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 70])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 87])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 41])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 112])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 41])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 74])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 81])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 72])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 49])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 50])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 38])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 47])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 38])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 112])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 72])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 61])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 46])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 82])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 77])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 55])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 43])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 196])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 39])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 74])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 40])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 154])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 55])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 41])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 52])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 92])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 69])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 55])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 95])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 65])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 95])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 55])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 89])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 89])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 39])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 41])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 56])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 68])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 42])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 56])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 44])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 52])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 40])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 82])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 154])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([64, 69])\n",
      "Labels Shape: torch.Size([64])\n",
      "Data Shape: torch.Size([19, 39])\n",
      "Labels Shape: torch.Size([19])\n"
     ]
    }
   ],
   "source": [
    "# Define our Dataset class\n",
    "class SMSDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer, vocab):\n",
    "        self.data = []\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                label, text = line.strip().split('\\t')\n",
    "                self.data.append((label, text))\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label, text = self.data[index]\n",
    "        encoded_label = 1 if label == 'spam' else 0\n",
    "        tokens = self.tokenizer(text)\n",
    "        numerical_tokens = [self.vocab[token] for token in tokens]\n",
    "\n",
    "        return torch.tensor(numerical_tokens), torch.tensor(encoded_label)\n",
    "\n",
    "    # to ensure that all batches have the same size\n",
    "    def collate_fn(self, batch):\n",
    "        data, labels = zip(*batch)\n",
    "\n",
    "        # Pad data and labels to the same length\n",
    "        padded_data = pad_sequence(data, batch_first=True)\n",
    "        padded_labels = torch.tensor(labels)\n",
    "\n",
    "        return padded_data, padded_labels\n",
    "\n",
    "# Create our training and testing datasets\n",
    "train_data = SMSDataset(train_file_path, tokenizer, vocab)\n",
    "test_data = SMSDataset(test_file_path, tokenizer, vocab)\n",
    "\n",
    "# Check sampling and batching. Make sure that all batches have the same size\n",
    "with torch.no_grad():\n",
    "    batch_size = 64\n",
    "    data, label = train_data[0]\n",
    "    print(\"Sample Data:\", data)\n",
    "    print(\"Sample Label:\", label)\n",
    "    data_loader = DataLoader(train_data,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=train_data.collate_fn)\n",
    "    for data, labels in data_loader:\n",
    "        print('Data Shape:', data.shape)\n",
    "        #print('Data Items Shape:', [data.shape for data in data])\n",
    "        print(\"Labels Shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1100,
     "status": "ok",
     "timestamp": 1692428275557,
     "user": {
      "displayName": "Eugene Emelyanov (yemel)",
      "userId": "15307913813243875076"
     },
     "user_tz": -120
    },
    "id": "HN8AfAVveKAw",
    "outputId": "1dfa6cd1-e550-4ab3-8edd-0099040c4d79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextClassifier(\n",
      "  (embedding): Embedding(3623, 100)\n",
      "  (lstm): LSTM(100, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n",
      "Predictions Shapes: torch.Size([64]) Labels: torch.Size([64])\n",
      "Predictions DataTypes: torch.float32 Labels: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# For simplicity, let's use an LSTM-based model\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size,\n",
    "                 embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 n_layers,\n",
    "                 bidirectional):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim,\n",
    "                            hidden_dim,\n",
    "                            num_layers=n_layers,\n",
    "                            bidirectional=bidirectional,\n",
    "                            batch_first=True\n",
    "                           )\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout( self.embedding(text) )\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "        return self.fc(hidden)\n",
    "\n",
    "# Initializer the model\n",
    "model = TextClassifier( vocab_size,\n",
    "                       embedding_dim=100,\n",
    "                       hidden_dim=256,\n",
    "                       output_dim=1,\n",
    "                       n_layers=2,\n",
    "                       bidirectional=True\n",
    "                      )\n",
    "# Check model summary\n",
    "print(model)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make sure that the model output and labels have the same shape and datatypes\n",
    "with torch.no_grad():\n",
    "    batch_size = 64\n",
    "    data_loader = DataLoader(train_data,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=train_data.collate_fn)\n",
    "    data, labels = next(iter(data_loader))\n",
    "    predictions = model(data).squeeze(1)\n",
    "    labels = labels.float()\n",
    "    print(\"Predictions Shapes:\", predictions.shape, \"Labels:\", labels.shape)\n",
    "    print(\"Predictions DataTypes:\", predictions.dtype, \"Labels:\", labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4568,
     "status": "ok",
     "timestamp": 1692428292941,
     "user": {
      "displayName": "Eugene Emelyanov (yemel)",
      "userId": "15307913813243875076"
     },
     "user_tz": -120
    },
    "id": "f-72A0w-eQpx",
    "outputId": "9069f5e5-dba9-4256-bbfc-dea9990a4e12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Class weights: tensor(6.4625)\n",
      "Average Loss: 0.0973\n"
     ]
    }
   ],
   "source": [
    "# Prepare the model for training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Define hyperparameters\n",
    "num_folds = 5\n",
    "num_epochs = 5\n",
    "batch_size = 128\n",
    "learn_rate = 0.001\n",
    "weight_decay = 0\n",
    "\n",
    "# Calculate imbalance ratios between \"ham\" and spam\n",
    "ham_count, spam_count = train_df['label'].value_counts()\n",
    "spam_ratio = spam_count / ham_count\n",
    "ham_ratio = ham_count / spam_count\n",
    "\n",
    "# Define class weights. We do it because we have quite unbalanced dataset\n",
    "class_weights = torch.tensor(1.0/ spam_ratio).to(device)\n",
    "\n",
    "# Define the loss function\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Check that everything is set\n",
    "print(\"Device:\", device)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# Make sure that our loss function works well\n",
    "with torch.no_grad():\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    batch_size = 64\n",
    "    data_loader = DataLoader(train_data,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=train_data.collate_fn)\n",
    "    total_loss = 0.0\n",
    "    for _ in range(5):\n",
    "        data, labels = next( iter(data_loader) )\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        predictions = model(data)\n",
    "        total_loss += loss_function(predictions.squeeze(), labels.float()).item()\n",
    "    average_loss = total_loss / len(data_loader)\n",
    "    print(f'Average Loss: {average_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2651591,
     "status": "ok",
     "timestamp": 1692430965238,
     "user": {
      "displayName": "Eugene Emelyanov (yemel)",
      "userId": "15307913813243875076"
     },
     "user_tz": -120
    },
    "id": "-ZRzOSC9eeoE",
    "outputId": "b9eb52c0-98eb-40c3-c5a6-397b34269bfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch [1/5], Train Loss: 0.7363, Validation Loss: 0.4175\n",
      "Fold 1, Epoch [2/5], Train Loss: 0.3784, Validation Loss: 0.3626\n",
      "Fold 1, Epoch [3/5], Train Loss: 0.2991, Validation Loss: 0.3653\n",
      "Fold 1, Epoch [4/5], Train Loss: 0.2267, Validation Loss: 0.3707\n",
      "Fold 1, Epoch [5/5], Train Loss: 0.1968, Validation Loss: 0.2911\n",
      "Fold 2, Epoch [1/5], Train Loss: 0.1958, Validation Loss: 0.1038\n",
      "Fold 2, Epoch [2/5], Train Loss: 0.1499, Validation Loss: 0.0871\n",
      "Fold 2, Epoch [3/5], Train Loss: 0.1285, Validation Loss: 0.0811\n",
      "Fold 2, Epoch [4/5], Train Loss: 0.0930, Validation Loss: 0.1458\n",
      "Fold 2, Epoch [5/5], Train Loss: 0.0983, Validation Loss: 0.1093\n",
      "Fold 3, Epoch [1/5], Train Loss: 0.1508, Validation Loss: 0.0373\n",
      "Fold 3, Epoch [2/5], Train Loss: 0.0771, Validation Loss: 0.0464\n",
      "Fold 3, Epoch [3/5], Train Loss: 0.0691, Validation Loss: 0.0540\n",
      "Fold 3, Epoch [4/5], Train Loss: 0.0409, Validation Loss: 0.0461\n",
      "Fold 3, Epoch [5/5], Train Loss: 0.0424, Validation Loss: 0.0577\n",
      "Fold 4, Epoch [1/5], Train Loss: 0.0744, Validation Loss: 0.0104\n",
      "Fold 4, Epoch [2/5], Train Loss: 0.0411, Validation Loss: 0.0042\n",
      "Fold 4, Epoch [3/5], Train Loss: 0.0382, Validation Loss: 0.0539\n",
      "Fold 4, Epoch [4/5], Train Loss: 0.0466, Validation Loss: 0.0167\n",
      "Fold 4, Epoch [5/5], Train Loss: 0.0595, Validation Loss: 0.0208\n",
      "Fold 5, Epoch [1/5], Train Loss: 0.0429, Validation Loss: 0.0233\n",
      "Fold 5, Epoch [2/5], Train Loss: 0.0346, Validation Loss: 0.0280\n",
      "Fold 5, Epoch [3/5], Train Loss: 0.0209, Validation Loss: 0.0084\n",
      "Fold 5, Epoch [4/5], Train Loss: 0.0059, Validation Loss: 0.0174\n",
      "Fold 5, Epoch [5/5], Train Loss: 0.0171, Validation Loss: 0.0258\n"
     ]
    }
   ],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, loss_function, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for data, labels in dataloader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(data)\n",
    "        batch_loss = loss_function(predictions.squeeze(1), labels.float())\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += batch_loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def validate(model, dataloader, loss_function, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data, labels in dataloader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            predictions = model(data)\n",
    "            total_loss += loss_function(predictions.squeeze(1), labels.float()).item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Cross-validation loop\n",
    "for fold, (train_indices, val_indices) in enumerate( kf.split(range(len(train_data))) ):\n",
    "    train_data_fold = Subset(train_data, train_indices)\n",
    "    val_data_fold = Subset(train_data, val_indices)\n",
    "\n",
    "    train_loader_fold = DataLoader(train_data_fold,\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=True,\n",
    "                                       collate_fn=train_data.collate_fn)\n",
    "    val_loader_fold = DataLoader(val_data_fold,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     collate_fn=train_data.collate_fn)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = optim.Adam( model.parameters(), lr=learn_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_one_epoch(model,\n",
    "                                     train_loader_fold,\n",
    "                                     optimizer,\n",
    "                                     loss_function,\n",
    "                                     device)\n",
    "        val_loss = validate(model,\n",
    "                            val_loader_fold,\n",
    "                            loss_function,\n",
    "                            device)\n",
    "        print(f'Fold {fold+1}, Epoch [{epoch+1}/{num_epochs}],',\n",
    "              f'Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20168,
     "status": "ok",
     "timestamp": 1692430990978,
     "user": {
      "displayName": "Eugene Emelyanov (yemel)",
      "userId": "15307913813243875076"
     },
     "user_tz": -120
    },
    "id": "3LqKTZsvgwoQ",
    "outputId": "8b1e8935-6bdb-4751-efb3-36948b2ea585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9763\n",
      "Precission:  0.8812\n",
      "Recall: 0.9519\n",
      "F1-score: 0.9152\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_loader = DataLoader(test_data,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=test_data.collate_fn)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    true_labels = np.array([])\n",
    "    pred_labels = np.array([])\n",
    "\n",
    "    for data, labels in test_loader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        predictions = model(data).squeeze(1)\n",
    "        rounded_preds = torch.round( torch.sigmoid(predictions) )\n",
    "        true_labels = np.concatenate(( true_labels, labels.cpu().numpy() ))\n",
    "        pred_labels = np.concatenate(( pred_labels, rounded_preds.cpu().numpy() ))\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    precision = precision_score(true_labels, pred_labels)\n",
    "    recall = recall_score(true_labels, pred_labels)\n",
    "    f1 = f1_score(true_labels, pred_labels)\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precission: {precision: .4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1-score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 449,
     "status": "ok",
     "timestamp": 1692431035041,
     "user": {
      "displayName": "Eugene Emelyanov (yemel)",
      "userId": "15307913813243875076"
     },
     "user_tz": -120
    },
    "id": "J9tD9yACG6M9",
    "outputId": "29176dba-df2f-41a7-a0a1-92afebce78eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.018541013821959496, 'ham']\n"
     ]
    }
   ],
   "source": [
    "# function to predict messages based on model\n",
    "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
    "def predict_message(pred_text):\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize the input text\n",
    "    tokens = tokenizer(pred_text)\n",
    "    numerical_tokens = [vocab[token] for token in tokens]\n",
    "\n",
    "    # Convert to a tensor and make a prediction\n",
    "    data = torch.tensor([numerical_tokens]).to(device)\n",
    "    with torch.no_grad():\n",
    "        prediction = torch.sigmoid(model(data)).item()\n",
    "    # Determine the label based on the prediction\n",
    "    label = 'spam' if prediction >= 0.5 else 'ham'\n",
    "\n",
    "    return [prediction, label]\n",
    "\n",
    "\n",
    "pred_text = \"how are you doing today?\"\n",
    "\n",
    "prediction = predict_message(pred_text)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 332,
     "status": "ok",
     "timestamp": 1692431041752,
     "user": {
      "displayName": "Eugene Emelyanov (yemel)",
      "userId": "15307913813243875076"
     },
     "user_tz": -120
    },
    "id": "Dxotov85SjsC",
    "outputId": "e8bac6c3-7826-4b5d-9dbf-3ee3f25ee8df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You passed the challenge. Great job!\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to test your function and model. Do not modify contents.\n",
    "def test_predictions():\n",
    "  test_messages = [\"how are you doing today\",\n",
    "                   \"sale today! to stop texts call 98912460324\",\n",
    "                   \"i dont want to go. can we try it a different day? available sat\",\n",
    "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
    "                   \"you have won £1000 cash! call to claim your prize.\",\n",
    "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
    "                   \"wow, is your arm alright. that happened to me one time too\"\n",
    "                  ]\n",
    "\n",
    "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
    "  passed = True\n",
    "\n",
    "  for msg, ans in zip(test_messages, test_answers):\n",
    "    prediction = predict_message(msg)\n",
    "    if prediction[1] != ans:\n",
    "      passed = False\n",
    "\n",
    "  if passed:\n",
    "    print(\"You passed the challenge. Great job!\")\n",
    "  else:\n",
    "    print(\"You haven't passed yet. Keep trying.\")\n",
    "\n",
    "test_predictions()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "https://github.com/freeCodeCamp/boilerplate-neural-network-sms-text-classifier/blob/master/fcc_sms_text_classification.ipynb",
     "timestamp": 1692106044479
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
